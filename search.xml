<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>合并二叉树</title>
      <link href="/2019/12/11/%E5%90%88%E5%B9%B6%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
      <url>/2019/12/11/%E5%90%88%E5%B9%B6%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>给定两个二叉树，想象当你将它们中的一个覆盖到另一个上时，两个二叉树的一些节点便会重叠。</p><a id="more"></a><p>你需要将他们合并为一个新的二叉树。合并的规则是如果两个节点重叠，那么将他们的值相加作为节点合并后的新值，否则不为 NULL 的节点将直接作为新二叉树的节点。</p><p>示例 1:</p><p>输入: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">Tree 1                     Tree 2                  </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">          1                         2                             </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">         &#x2F; \                       &#x2F; \                            </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">        3   2                     1   3                        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">       &#x2F;                           \   \                      </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">      5                             4   7</span></pre></td></tr></table></figure><p>输出: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">合并后的树:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">     3</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    &#x2F; \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">   4   5</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">  &#x2F; \   \ </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"> 5   4   7</span></pre></td></tr></table></figure><p>注意: 合并必须从两个树的根节点开始。</p><p>如果1子树为空，则返回2子树，如果2子树为空，则返回1子树，若都不为空，则相加节点的值，利用递归同时进行遍历。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&#x2F;**</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"> * Definition for a binary tree node.</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"> * struct TreeNode &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"> *     int val;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"> *     struct TreeNode *left;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"> *     struct TreeNode *right;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"> * &#125;;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"> *&#x2F;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">struct TreeNode* mergeTrees(struct TreeNode* t1, struct TreeNode* t2)&#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    if(t2&#x3D;&#x3D;NULL) return t1;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    else if(t1&#x3D;&#x3D;NULL) return t2;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    t1-&gt;val+&#x3D;t2-&gt;val;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    t1-&gt;left&#x3D;mergeTrees(t1-&gt;left,t2-&gt;left);</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    t1-&gt;right&#x3D;mergeTrees(t1-&gt;right,t2-&gt;right);</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    return t1;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">&#125;</span></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二叉树 </tag>
            
            <tag> 链表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于中断循环神经网络的文本分类</title>
      <link href="/2019/12/11/%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E%EF%BC%9A%E5%9F%BA%E4%BA%8E%E4%B8%AD%E6%96%AD%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
      <url>/2019/12/11/%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E%EF%BC%9A%E5%9F%BA%E4%BA%8E%E4%B8%AD%E6%96%AD%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="ACL-2018-：科大讯飞：基于中断循环神经网络的文本分类"><a href="#ACL-2018-：科大讯飞：基于中断循环神经网络的文本分类" class="headerlink" title="ACL 2018 ：科大讯飞：基于中断循环神经网络的文本分类"></a>ACL 2018 ：科大讯飞：基于中断循环神经网络的文本分类</h1><p><a href="https://www.aclweb.org/anthology/P18-1215" target="_blank" rel="noopener">原文:Disconnected Recurrent Neural Networks for Text Categorization</a></p><p>基于中断循环神经网络的文本分类</p><p>科大讯飞北京研究院HFL实验室</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>文本分类任务是自然语言处理（NLP）领域最基础和传统的任务之一，该任务又会根据领域类型的不同分成很多子任务，例如情感分类、主题分类和问题分类等。很多机器学习的新方法都会先尝试在文本分类任务上进行实验验证。例如深度学习中最常见的两大类模型，卷积神经网络（CNN）和循环神经网络（RNN）及其变体，在文本分类中有很多应用。</p><p>RNN模型擅长对整个句子进行建模，捕捉长距离依赖信息。然而研究表明，RNN对整个句子建模有时会成为一种负担，使模型忽略了关键的短语信息。CNN模型则正相反，更擅长抽取局部的位置不变特征，而不擅长捕捉长距离依赖信息。为此，我们提出了DRNN模型，通过限制RNN模型信息的流动，将位置不变性引入RNN模型中。这使得DRNN模型既能捕捉长距离依赖信息，又可以很好地抽取关键短语信息。我们提出的模型在DBPedia，Yelp等多个文本分类数据集上取得了最好的效果。</p><h2 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h2><p>表1是一个主题分类的例子，我们可以看到两句话表意基本相同，都应该被分类到科技类。其中决定分类的关键短语是“unsolved mysteries of mathematics”，对于一个窗口大小为4的CNN模型来说，两个句子中的该短语表示完全相同。然而，当我们把两句话送入RNN模型的时候，因为RNN模型中，每一个时刻的隐层状态都和前面所有词语相关，所以这两个短语的表示是完全不同的。这增大了模型捕捉关键短语的难度，使得RNN模型有时会忽视一些关键信息。</p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20180609/794d1ebdc79e47dc81eec2e8db633dbf.jpg" alt="image"></p><p>表格1 主题分类示例</p><p>为了解决上述问题，我们希望通过将位置不变性引入RNN模型中，使得RNN模型既可以捕捉长距离依赖信息，又可以更好地抽取位置不变的局部特征。具体来说，我们会阻断RNN模型的信息流动，使其最多只能传递固定的步长k。这样的话，每个时刻的隐层状态就只和当前词以及前k-1个词相关。</p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20180609/0e6af5ff646049b3a3ccf6c0a14e98f2.jpg" alt="image"></p><p>图1 Disconnected Recurrent Neural Networks</p><p>图1是RNN模型、DRNN模型和CNN模型的一个对比图。如图所示，对于RNN来说，隐层状态h与前面所有的词都相关，而对于DRNN，则只与当前词及之前的k-1个词相关。DRNN模型也可以被认为是一种特殊的CNN模型，只是将CNN模型中的卷积核替换成了RNN。显然，DRNN和CNN一样，对于长度为k的短语，无论它在文本中的什么位置，都具有相同的表示。DRNN模型t时刻的隐藏层输出可以表示成如下形式：<br><img src="http://5b0988e595225.cdn.sohucs.com/images/20180609/7fca22c694154eaaaaed8527ccb10c6a.jpg" alt="image"></p><p>DRNN是一种通用的模型框架，可以应用在很多任务中，我们主要将其应用在文本分类任务中，对应的模型结构见图2。我们采用GRU作为DRNN的循环单元，得到Disconnected Gated Recurrent Unit（DGRU）模型。我们首先将DGRU的每个隐层表示送入MLP中，来抽取更高层的特征信息。然后再通过Max Pooling来抽取整个文本中最重要的信息，最后再通过一层MLP，然后送入softmax中进行分类。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 文本分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于卷积</title>
      <link href="/2019/12/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF/"/>
      <url>/2019/12/11/%E5%85%B3%E4%BA%8E%E5%8D%B7%E7%A7%AF/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="对卷积的困惑"><a href="#对卷积的困惑" class="headerlink" title="对卷积的困惑"></a>对卷积的困惑</h1><p>教科书上一般定义函数f,g的卷积f*g(n)如下：</p><p>连续形式</p><p><img src="https://www.zhihu.com/equation?tex=%28f%2Ag%29%28n%29%3D%5Cint_%7B-%5Cinfty+%7D%5E%7B%5Cinfty%7Df%28%5Ctau+%29g%28n-%5Ctau%29d%5Ctau" alt="image"></p><p>离散形式</p><p><img src="https://www.zhihu.com/equation?tex=%28f%2Ag%29%28n%29%3D%5Csum_%7B%5Ctau%3D-%5Cinfty+%7D%5E%7B%5Cinfty%7Df%28%5Ctau%29g%28n-%5Ctau%29" alt="image"></p><h3 id="对卷积的理解"><a href="#对卷积的理解" class="headerlink" title="对卷积的理解"></a>对卷积的理解</h3><p>整体看来是这么个过程：</p><p>翻转——&gt;滑动——&gt;叠加——&gt;滑动——&gt;叠加——&gt;滑动——&gt;叠加…..</p><p>多次滑动得到的一系列叠加值，构成了卷积函数。</p><h4 id="例1⃣：信号分析"><a href="#例1⃣：信号分析" class="headerlink" title="例1⃣：信号分析"></a>例1⃣：信号分析</h4><p>如下图所示，输入信号是 f(t) ，是随时间变化的。系统响应函数是 g(t) ，图中的响应函数是随时间指数下降的，它的物理意义是说：如果在 t=0 的时刻有一个输入，那么随着时间的流逝，这个输入将不断衰减。换言之，到了 t=T时刻，原来在 t=0 时刻的输入f(0)的值将衰减为f(0)g(T)。</p><p><img src="https://pic1.zhimg.com/80/v2-59c8bcf17c24119810ad3071b960f1ba_hd.jpg" alt="image"></p><p>考虑到==信号是连续输入的，也就是说，每个时刻都有新的信号进来，所以，最终输出的是所有之前输入信号的累积效果==。如下图所示，在T=10时刻，输出结果跟图中带标记的区域整体有关。其中，f(10)因为是刚输入的，所以其输出结果应该是f(10)g(0)，而时刻t=9的输入f(9)，只经过了1个时间单位的衰减，所以产生的输出应该是f(9)g(1)，如此类推，即图中虚线所描述的关系。这些对应点相乘然后累加，就是T=10时刻的输出信号值，这个结果也是f和g两个函数在T=10时刻的卷积值。<br><img src="https://pic1.zhimg.com/80/v2-de38ad49f9a1c99dafcc5d0a7fcac2ef_hd.jpg" alt="image"></p><p>累积效果可以将g函数对折一下，变成g(-t)，这就是为什么卷积要“卷”，要翻转的原因，这是从它的物理意义中给出的。<br><img src="https://pic4.zhimg.com/80/v2-5d5ca564c8f0eaba9cd9865a9c944fbb_hd.jpg" alt="image"><br>然后再进行T个单位的平移就可以得到<br><img src="https://pic4.zhimg.com/80/v2-847a8d7c444508862868fa27f2b4c129_hd.jpg" alt="image"><br>所以，在以上计算T时刻的卷积时，要维持的约束就是： t+ (T-t) = T</p><h4 id="例2⃣：丢骰子"><a href="#例2⃣：丢骰子" class="headerlink" title="例2⃣：丢骰子"></a>例2⃣：丢骰子</h4><p>要解决的问题是：有两枚骰子，把它们都抛出去，两枚骰子点数加起来为4的概率是多少?</p><p><img src="https://pic1.zhimg.com/80/v2-a5238ad7dfccc0f2645e1c34c10a19c9_hd.jpg" alt="image"></p><p>​​分析一下，两枚骰子点数加起来为4的情况有三种情况：1+3=4， 2+2=4, 3+1=4因此，两枚骰子点数加起来为4的概率为：</p><p><img src="https://pic4.zhimg.com/80/v2-e5a05d465fc32d4e880f7d77e811fb7e_hd.jpg" alt="image"></p><p>写成卷积的方式就是：​</p><p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+%28f%2Ag%29%284%29%3D%5Csum+_%7Bm%3D1%7D%5E%7B3%7Df%284-m%29g%28m%29%5C%5C" alt="image"></p><p>还用反转滑动叠加的逻辑进行解释，将函数g翻转，然后阴影区域上下对应的数相乘，然后累加，相当于求自变量为4的卷积值，如下图所示：<br><img src="https://pic4.zhimg.com/80/v2-c6d14a16dee215b2d6b9e020aefd2542_hd.jpg" alt="image"><br>​​进一步，如此翻转以后，可以方便地进行推广去求两个骰子点数和为 n 时的概率，为f 和 g的卷积 f*g(n)，如下图所示：​<br><img src="https://pic4.zhimg.com/80/v2-860cdc53a489be168e9a12845c7eadc4_hd.jpg" alt="image"><br>由上图可以看到，函数 g 的滑动，带来的是点数和的增大。这个例子中对f和g的约束条件就是点数和，它也是卷积函数的自变量。有兴趣还可以算算，如果骰子的每个点数出现的概率是均等的，那么两个骰子的点数和n=7的时候，概率最大。</p><hr><p>由上图可以看到，函数 g 的滑动，带来的是点数和的增大。这个例子中对f和g的约束条件就是点数和，它也是卷积函数的自变量。有兴趣还可以算算，如果骰子的每个点数出现的概率是均等的，那么两个骰子的点数和n=7的时候，概率最大。</p>]]></content>
      
      
      <categories>
          
          <category> 基础支撑 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/12/09/hello-world/"/>
      <url>/2019/12/09/hello-world/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo server</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo generate</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>对话中的情感识别</title>
      <link href="/2019/12/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91DialogueGCN%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AF%B9%E8%AF%9D%E4%B8%AD%E8%BF%9B%E8%A1%8C%E6%83%85%E6%84%9F%E8%AF%86%E5%88%AB/"/>
      <url>/2019/12/08/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91DialogueGCN%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AF%B9%E8%AF%9D%E4%B8%AD%E8%BF%9B%E8%A1%8C%E6%83%85%E6%84%9F%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>EMNLP 2019 </p><p>DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation<br><a href="https://arxiv.org/pdf/1908.11540.pdf" target="_blank" rel="noopener">原文pdf</a> </p><a id="more"></a><hr><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><blockquote><p>Emotion recognition in conversation (ERC) has received much attention, lately, from re- searchers due to its potential widespread applications in diverse areas, such as health-care, education, and human resources. In this paper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph neural network based approach to ERC. We leverage ==self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition==. Through the graph network, DialogueGCN addresses context propagation issues present in the current RNN-based methods. We empirically show that this method alleviates such issues, while outperforming the current state of the art on a number of benchmark emotion classification datasets.</p></blockquote><h3 id="研究背景—什么是情感识别？"><a href="#研究背景—什么是情感识别？" class="headerlink" title="研究背景—什么是情感识别？"></a>研究背景—什么是情感识别？</h3><p>最近，深度学习在自然语言处理领域（NLP）取得了很大的进步。随着诸如 Attention 和 Transformers 之类新发明的出现，BERT 和 XLNet 一次次取得进步，使得文本情感识别之类的等任务变得更加容易。本文将介绍一种新的方法，该方法使用图模型在对话中进行情感识别。</p><h4 id="什么是情感识别？"><a href="#什么是情感识别？" class="headerlink" title="什么是情感识别？"></a>什么是情感识别？</h4><p>简而言之，情感识别（ERC）是对文字背后的情感进行分类的任务。例如，给定一段文字，你能说出说话者是生气、快乐、悲伤还是困惑吗？情感识别在医疗保健、教育、销售和人力资源方面具有许多广泛的应用。从最高的一个层面讲，情感识别任务非常有用，因为许多人认为，这是构建能够与人类对话的智能 AI 的基石。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 情感分析 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
